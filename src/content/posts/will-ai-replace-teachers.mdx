---
title: "Will AI replace teachers?"
date: "2025-09-16"
tags: ["teaching"]
description: "Is AI coming for our jobs"
imageUrl: "/images/robot.jpg"
imageAlt: "Image of a robot"
draft: false
youtubeId: "3CuqbqEAp-w"
---
import YouTubeEmbed from "../../components/YouTubeEmbed.astro";

<YouTubeEmbed 
  videoId="3CuqbqEAp-w"
  title="Will AI replace teachers?"
/>

AI can already write lessons, quizzes, even whole courses. So do we still need teachers?

I get asked this a lot â€” will developer educators even exist in 5 years?

Hi, Iâ€™m Kevin, and I'm on a mission to help developers share their knowledge in the most impactful ways possible.

Soâ€¦ is AI about to put me out of a job? 

Let's explore this together and see 

## Information vs Education

When I first get asked this question, I think about the difference between information and education. LLMs are fantastic at delivering information at scale - have a question, here's an answer! Conveyed with a lot of confidence and not always the most accuracy. We can definitely improve these responses with better prompts and context but it requires the inquirer to know what questions to ask. 

But training is more than just information, it's guiding, it's motivating and it's contextualising. My job as a teacher is not to download information into brains, rather it's to craft training that will turn knowledge into understanding and action. I want to leave my students with a map of knowledge that they can use AI to further enhance and zoom in on as they need it. Importantly, I want to equip folks with the tools and frameworks to know which questions to ask and when.

That way, they are in a better position to course correct when their AI buddies go off the deep end and maybe anticipate these problems as they enhance the context with their own deeper understanding.

## Adaptability & Calibration

I've definitely started conversations with an LLM with a very broad and unspecific question, hoping for insights in an area where I have no grounding at all. Now, models are constantly improving and able to take my poorly phrased questions and infer meaning but without careful prompting the direction might be wrong. It may be outdated as the LLMs context has changed and the data the AI was trained on may be out of date.

As a teacher in a room - physical or virtual - I'm constantly reading what's going on. My context window is constantly being informed by the facial expressions, body language and questions that my students are asking. That helps me to adjust the examples, explain differently when folks are lost and adapt based on the energy and experience in the room.

Back when I was a Maths teacher, I'd tell my students that my job was to help them to understand these concepts before they left the room. Their job was to keep telling me whether they understood it or not. Importantly, if they didn't understand it, I wasn't going to repeat it louder, instead I was going to use a different metaphor or example or approach to try to make it stick more.

This is just as true for me as I work with developers. I'm adapting and calibrating my content and examples all the time - helping this group of humans deepen their understanding and gain confidence as they gain skills and knowledge.

## **Human Connection & Trust**

I don't think I'd sign up to go to a conference if it was just a series of talks delivered by LLMs. In having humans speak from a stage, I gain insights into real world problems and human stories.

When I lead training, it's normally in groups of 10-20 developers who all work at the same company. This time has been put aside to come together and learn something new. I get to create a safe environment to allow us to make mistakes, ask questions and share successes and failures. I want to bring my lived experience as a developer, questions and challenges that other teams in similar or contrasting contexts are facing and, hopefully, credibility that I'm not hallucinating or making things up.

Eliza, the first therapy chat bot, tried to build empathy by repeating phrases. As a human, I'm doing that by actively listening and engaging with the problems and questions that my students have. I think we still have the edge here.
### 4. **Critical Thinking & Values**

As humans with technical expertise, we're able to explain the reasoning behind critical thinking decisions. While AI can produce options, it struggles with discernment. It doesn't always know what it doesn't know.

As trainers, we can ask questions, share past experiences and help make decisions that are relevant to the folks in front of us. Whether I'm teaching at CERN and helping engineers and scientists there deal with large amounts of experimental data or at the BBC where we need reliable uptime and constant availability - I can help bring values and critical thinking in a way that AI can't.

Alongside the actual technical training, we can bring out ethical considersations, model collaborative workflows and generally help folks embed their thinking in the human context that they are going to be working and using these skills in.

---
### 5. **AI as a Tool, Not a Replacement**

I am not anti-AI - I use it to help speed my prep up, generate some of my examples and help to personalise learning. But I use it as a tool and not a replacement. And my students are equipped to go ahead and help to leverage AI as a way to extend their knowledge and skills.

Whether it's a deep dive into a lesser known part of the Python or Java ecosystem or an introduction to using TypeScript - I am able to set students up with a map - bringing clarity with diagrams, body language, words and text - I want to make sure that when I'm gone, when our 2,3,4,5 day engagement is over - that these developers are equipped to know how and where AI can fit into their workflow. Which questions they can and should rely on AI, where they should be cautious and suspicious and when they can rely on their own knowledge - helping them to trust the tacit understanding they have of their own circumstances and their own growing knowledge of the languages and frameworks they are using.

I first started teaching secondary Maths in 2004. Some of my colleagues then were still grumpy about calculators - but calculators didn't remove maths teachers - it changed some of what and how we taught - and I see AI as a similar tool. A way to help us avoid tedium and focus on delivering interesting, valuable and useful tools. 

---
## ðŸ’¡ Wrap-Up
So, do we still need teachers in the age of AI? I might be biased as someone who spends most of my worklife teaching developers but I think the answer is absolutely. 

I think my role is evolving though - my courses have changed, my examples have altered, how I encourage students to work on examples and labs has changed - real learning happens when folks retrieve knowledge for themselves - AI can't do that for us and I think trainers have an opportuntiy to help coach and faciliate deep and meaningful learning. 

We're there to coach, to faciliate - to help draw connections out into the open - things that AI won't necessarily draw attention to unless specifically asked - and, for the most part, this links are not things that folks actually ask for. An expert leading the learning helps to accelerate the understanding, creating safe spaces for questions and exploration - allowing humans to deepen their awareness and understanding of complex technical topics.

That's all from me - keep doing and keep learning!

